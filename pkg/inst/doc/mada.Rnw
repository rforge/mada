%\VignetteIndexEntry{Meta Analysis of Diagnostic Accuracy with mada}
%\VignetteKeyword{meta analysis, diagnostic test}

\documentclass[a4paper]{article}
\usepackage{a4wide}
\usepackage{amsmath,color,amsthm}
\usepackage{url}
\usepackage{hyperref}

\DeclareMathOperator{\logit}{logit}
\DeclareMathOperator{\T}{T}


\title{Meta Analysis of Diagnositc Accuracy with \texttt{mada}}
\author{Philipp Doebler \\
      philipp.doebler@googlemail.com}

\begin{document}

\maketitle

\section{Introduction}
While substantial work has been conducted on methods for diagnostic meta-analysis, it has not become a routine procedure yet. One of the reasons for this is certainly the complexity of bivariate approaches, but another reason is that standard software packages for meta-analysis, for example \emph{Comprehensive Meta-Analysis} (\cite{}), do not include software to fit models appropriate for diagnostic meta-analysis. For the recommended (\cite{}) bivariate approach of Rutter and Gatsonis (TODO: citation) meta-analysts can use Bayesian approaches (for example in WinBUGS or OpenBUGS\cite{}), the stata macro (TODO: is it called macro?) of \cite{Harbord}, ...(TODO: andere Software raussuchen). So currently available software is either relatively complex (WinBUGS/OpenBUGS) or proprietary (stata, SAS).

The open source R-package \texttt{mada} provides some established and some current approaches to diagnostic meta-analysis, as well as functions to produce descriptive statistics and graphics. It is hopefully complete enough to be the only tool needed for a diagnostic meta-analysis. \texttt{mada} has been developed with an R user in mind that has used standard model fitting functions already, and a lot of the output of \texttt{mada} will look familiar to such a user. While this vignette cannot provide an introduction to R, it is hopefully detailed enough to provide a novice R user with enough hints to perform diagnostic meta-analysis along the lines of it. Free introductions to R are available on the homepage of the R project (\href{http://www.r-project.org/}. We assume that the reader is reasonably familiar with central concepts of (diagnostic) meta analysis, like fixed and random effects models and (S)ROC curves.

\section{Obtaining \texttt{mada}}
Once R is installed and an internet connection is available, the package can be installed from CRAN on most systems by typing
<<eval=FALSE>>=
install.packages("mada")
@
Development of \texttt{mada} is hosted at \texttt{http://r-forge.r-project.org/projects/mada/}; the most current version is available there\footnote{For example by typing \texttt{install.packages("mada", repos="http://R-Forge.R-project.org")} at an R prompt.}, while only stable versions are available from CRAN. The package can then be loaded:
<<>>=
library(mada)
@

\section{Entering data}
Primary diagnostic studies observe the result of a \emph{gold standard} procedure which defines the presence or absence of a \emph{condition}, and the result of a  \emph{diagnostic test} (typically some kind of low cost procedure, or at least one that is less invasive than the gold standard). Data from such a primary study could be reported in a $2\times2$, see Table \ref{2times2}.

\begin{table}[h]\caption{Data from the $i$th study in a $2\times2$ table}\label{2times2}
\begin{center}
\begin{tabular}[tbp]{lcc}\hline
  		&with condition &without condition \\
\hline
Test positive	& $y_i$		& $z_i$ \\
Test negative	& $m_i-y_i$ 	&$n_i-z_i$\\ 
\hline
Total&$m_i$&$n_i$\\ \hline
\end{tabular}
\end{center}
\end{table}

The numbers $y_i$ and $z_i$ are the numbers of true-positives (TP) and false positives (FP), respectively, and $m_i-y_i$ and $n_i-z_i$ are the numbers of false negatives (FN) and true negatives (TN). Often derived measures of diagnostic accuracy are calculated from 2$\times$2 tables. Using the notation in Table \ref{2times2}, one can calculate

\begin{eqnarray}
\text{sensitivity}_i  &=& \frac{y_i}{m_i}\\
\text{specificity}_i  &=& \frac{n_i - z_i}{n_i}\\
\text{false positive rate}_i &=& \frac{z_i}{n_i}.
\end{eqnarray}

The \texttt{mada} package needs the 2$\times$2 tables. We can use R to calculate the table given specificities or sensitivities if the sample size in each group is known (sometimes there is insufficient data to reconstruct the 2$\times$2 table). The above formulae for the sensitivity for example implies that
\[
y_i = m_i\text{sensitivity}_i.
\]
If a primary study reports a sensitivity of .944 and that there were 142 people with the condition, we can calculate $y$ by
<<>>=
y <- 142 * .944 
y
@
Since this is not an integer, we need to round it to the nearest integer
<<>>=
round(y)
@
Let us now assume that the number of TP, FP, FN and TN is known for each primary study. A good way to organise information in R is to use \emph{data frames}, which can hold different variables. In our case each row of the data frame corresponds to one primary study. As an example we enter the data from six studies from the AUDIT-C meta-analysis of (TODO: Zitat) into a data frame
<<>>=
AuditC6 <- data.frame(TP = c(47, 126, 19, 36, 130, 84),
                      FN = c(9, 51, 10, 3, 19, 2),
                      FP = c(101, 272, 12, 78, 211, 68),
                      TN = c(738, 1543, 192, 276, 959, 89))
AuditC6
@
Note that many central functions in \texttt{mada} also accept four vectors of frequencies (TP, FN, FP, TN) as input. Nevertheless, it is convenient to store not only the observed frequencies, but also the study names in the same data frame. The following command shows how to do this for our shortened example:
<<>>=
AuditC6$names <- c("Study 1","Study 2","Study 4","Study 4","Study 5","Study 6")
@
The full data set with 14 studies is part of \texttt{mada}; 
let's load the data set and have a look at the last six studies:
<<>>=
data(AuditC)
tail(AuditC)
@
In the following we will use the \texttt{AuditC} data set as a running example. The reader is encouraged though to see what happens if only the first 6 studies are used in the subsequent calculations.

\subsection{Zero cells}
In the analysis of data in 2$\times$2 tables zero cells often lead to problems or statistical artefacts since certain ratios do not exist. So called \emph{continuity corrections} are added to the observed frequencies; these are small positive numbers. One suggestions in the literature is to use $0.5$ as the continuity correction, which is the default value in \texttt{mada}. All functions in \texttt{mada} allow user specified continuity corrections and the correction can be applied to all studies, or just to those with zero cells.


\section{Descriptive statistics}
Descriptive statistics for a data set include the sensitivity, specificity and false-positive rate of the primary studies and also their positive and negative likelihood ratios, and their diagnostic odds ratio (DOR; TODO: Zitat einbauen). These are defined as
\[
\mathrm{posLR} = sensitivity/false positive rate,
\]
\[
\mathrm{negLR} = (1-sensitivity)/specificity,
\]
and
\[
\mathrm{DOR} = \mathrm{posLR}/\mathrm{negLR} = \frac{\mathrm{TP}\mathrm{TN}}{\mathrm{FN}\mathrm{FP}}.
\]
All these are easily computed for each study using the \texttt{madad} function, together with their confidence intervals (Zitat auf  Deeks JJ. Systematic reviews of evaluations of diagnostic and screening tests. In Egger M, Smith GD, Altman DG (eds). Systematic Reviews in Health Care. Meta-analysis in context. London: BMJ Books; 2001:248-282.). \texttt{madad} also performs $\chi^2$ tests to assess heterogeneity of sensitivities and specificities, the null hypothesis being in both cases, that all are equal. Finally the correlation of sensitivities and false positive rates is calculated to give a hint whether the cut-off value problem is present. The following output is slightly cropped.
<<eval=FALSE>>=
madad(AuditC)
@
\begin{Soutput}
Descriptive summary of AuditC with 14 primary studies.
Confidence level for all calculations set to 95 %
Using a continuity correction of 0.5 if applicable 

Diagnostic accuracies 
       sens  2.5% 97.5%  spec  2.5% 97.5%
 [1,] 0.833 0.716 0.908 0.879 0.855 0.899
 [2,] 0.711 0.640 0.772 0.850 0.833 0.866
...
[14,] 0.748 0.684 0.802 0.749 0.702 0.792

Test for equality of sensitivities: 
X-squared = 272.3603, df = 13, p-value = <2e-16
Test for equality of specificities: 
X-squared = 2204.8, df = 13, p-value = <2e-16

Diagnostic OR and likelihood ratios 
           DOR   2.5%     97.5%  posLR  2.5%  97.5% negLR  2.5% 97.5%
 [1,]   36.379 17.587    75.251  6.897 5.556  8.561 0.190 0.106 0.339
...
[14,]    8.850  5.949    13.165  2.982 2.448  3.632 0.337 0.264 0.430

Correlation of sensitivities and false positive rates: 
   rho  2.5 % 97.5 % 
 0.677  0.228  0.888 
\end{Soutput}
For the AUDIT-C data, the underlying call to \texttt{prop.test} produces a warning which should not worry us here. The \texttt{madad} function has a range of options with respect to computational details; for example one can compute 80\% confidence intervals:
<<eval=FALSE>>=
madad(AuditC, level = 0.80)
@
Also note that all the output of \texttt{madad} is available for further computations if one assigns the output of \texttt{madad} to an object. For example the false positive rates with their confidence intervals can be extracted  using the \texttt{$} construct:
<<eval=FALSE>>=
AuditC.d <- madad(AuditC)
AuditC.d$fpr
@
\subsection{Descriptive graphics}
For the AUDIT-C data, the $\chi^2$ tests already suggested heterogeneity of sensitivities and specificities. The corresponding \emph{forest plots} confirm this:
<<eval=FALSE>>=
forest(madad(AuditC), type = "sens")
forest(madad(AuditC), type = "spec")
@
A slightly enhanced version of these plots is shown in Figure \ref{forestplots}.

Apart from these univariate graphics \texttt{mada} provides a variety of plots to study the data on ROC space. Note that for exploratory purposes it is often useful to employ color and other features of R's plotting system. Two high level plots are provided by \texttt{mada}: \texttt{crosshair} to produce Crosshair plots (TODO: Zitat auf Philipps paper), and \texttt{ROCellipse}. The following is an example of a call of \texttt{crosshair} that produces (arbitrarily) colored crosshairs and makes the crosshairs wider with increased sample size; also only a portion of ROC space is plotted.
<<>>=
## calculate weights:
rs <- rowSums(AuditC)
rs <- 4 * rs/max(rs)
crosshair(AuditC, xlim = c(0,0.6), ylim = c(0.4,1), col = 1:14, lwd = rs)
@
\texttt{ROCellipse} plots confidence regions which describe the uncertainty of the pair of sensitivity and false positive rate. These regions are ellipses on logit ROC space, and by backtransforming them to regular ROC space the (sometimes oddly shaped) regions are produced. By default this function will also plot the point estimates. The following example is a bit contrived: here the plotting of the point estimates is suppressed manipulating the \texttt{pch} argument, but then points are added in the next step.
<<>>=
ROCellipse(AuditC, pch = "")
points(fpr(AuditC), sens(AuditC))
@
Figure \ref{diagplots} displays the two descriptive plots.

\section{Univariate Approaches}
Before the advent of the bivariate approaches by (TODO: Zitat Rutter Gatsonis) and (TODO: Zitat Reitsma et al), some univariate approaches diagnostic accuracy where popular. Bivariate approaches can only be recommended though, if the sample size is reasonably large; the bivariate model of (TODO: zitat) for example has 5 parameters, which would clearly be too much for a handful of studies. Hence \texttt{mada} provides some univariate methods. Since pooling sensitivities or specificities can be misleading (TODO: Zitat), options for the univariate meta-analysis of these are not provided. \texttt{mada} does provide approaches for the DOR (TODO: zitat glas), the positive and negative likelihood ratios, and the $\theta$, the accuracy parameter of the proportional hazards model for diagnostic meta analysis (TODO: Zitat). In this vignette we explain the details on the DOR methodology and the methods for $\theta$.

\subsection{Diagnostic odds ratio}
In analogy to the meta analysis of the odds ratio (OR) methods for the meta-analysis of the DOR can be developed (TODO: Zitate). For the \emph{fixed effects} case a Mantel-Haenszel (MH; see for example Deeks et al chapter 16) is provided by \texttt{mada}. The underlying fixed effects model has the form
\[
\mathrm{DOR}_i = \mu + \epsilon_i,
\]
where $\mu$ is true underlying DOR and the $\epsilon_i$ are independent errors with mean 0 and study specific varianz. The MH estimator is a weighted average of DORs observed in the primary studies and is robust to the presence of zero cells. It takes the form
\[
\hat \mu = \sum_i \frac{\omega_i^{MH} \mathrm{DOR}_i}{\sum_i \omega_i^{MH}},
\]
where $\omega_i^{MH} = \frac{z_i(m_i - y_i)}{m_i + n_i}$ are the Mantel-Haenszel weights.

One obtains an estimator for a \emph{random effects} model following the approach of DerSimonian-Laird (DSL; TODO: zitat). Here the underlying model is in terms of the $\log$ DORs. One assumes
\[
\log\mathrm{DOR}_i = \mu + \epsilon_i + \delta_i,
\]
where $\mu$ is the mean of the $\log$ DORs, $\epsilon_i$ and $\delta_i$ are independent with mean 0; the variance $\sigma_i^2$ of $\epsilon_i$ is estimated as
\[
\hat\sigma_i^2 = \frac{1}{y_i} + \frac{1}{m_i - y_i} +\frac{1}{z_i}  + \frac{1}{n_i -z_i}, 
\]
and the variance $\tau^2$ of $\delta_i$ is to be estimated. The DSL estimator then is a weighted estimator, too:
\[
\hat\mu = \sum_i\frac{\omega_i^{DSL} \mathrm{DOR}_i}{\sum_i \omega_i^{DSL}},
\]
where
\[
\omega_i^{DSL} = \frac{1}{\hat\sigma_i^2 + \tau^2}.
\]
The variance $\tau^2$ is estimated by the Cochran $Q$ statistic trick.

The function \texttt{madauni} handles the meta-analysis of the DOR (and the negative and positive likelihood ratios). One can use \texttt{madauni} in the following fashion:
<<>>=
(fit.DOR.DSL <- madauni(AuditC))
(fit.DOR.MH <- madauni(AuditC, method = "MH"))
@
Note that the brackets around \texttt{fit.DOR.DSL <- madauni(AuditC)} are a compact way to print the fits. The \texttt{print} method for \texttt{madauni} objects is not very informative, only the point estimate is returned along with (in the random effects case) an estimate of the $\tau^2$, the variance of the random effects. Note that estimation in the random effects case is performed on log-DOR scale, so that the variance of in the above DSL fit is substantial. To obtain more information the \texttt{summary} method can be used:
<<>>=
summary(fit.DOR.DSL)
@
In addition to the confidence intervals, Cochran's $Q$ statistic (TODO: Zitat) can be seen and Higgins $I^2$ (TODO Zitat).

\subsection{Proportional hazards model approach}
The proportional hazards model approach (PHM, TODO: Zitat) builds on the assumption of a simple form of the ROC curves. The so called \emph{Lehmann model} (TODO: Zitat) is assumed. Let $p_i$ and $u_i$ denote the $i$th study's sensitivity and false positive rate  respectively. The relationship of $p_i$ and $u_i$ is then assumed to be
\[
p_i = u_i^{\theta_i}, 
\]
where $\theta_i > 0$ is a diagnostic accuracy parameter. The smaller $\theta$, the larger the area under the ROC curve and thus the more accurate the diagnostic test. For the meta analysis of $\theta$ the APMLE estimator is implemented in \texttt{mada} for the case of homogeneity (i.e. fixed effects) and heterogeneity (i.e. random effects). Again the standard output of the \texttt{phm} function is rather sparse:
<<>>=
(fit.phm.homo <- phm(AuditC, hetero = FALSE))
(fit.phm.het <- phm(AuditC))
@
The \texttt{summary} method is more informative:
<<>>=
summary(fit.phm.homo)
@
The $\chi^2$ test goodness of fit test rejects the assumption of homogeneity, but the fit of the model for heterogeneity is better:
<<>>=
summary(fit.phm.het)
@
The estimation of $\theta$ results in an SROC curve (TODO: Zitate auf SROC papers); plotting this curve together with confidence bands obtained from the confidence interval of $\theta$ in the summary is simple (we also add the original data on ROC space with confidence regions and only plot a portion of ROC space):
\begin{center}
<<fig = TRUE>>=
plot(fit.phm.het, xlim = c(0,0.6), ylim = c(0.4,1))
ROCellipse(AuditC, add = TRUE)
@
\end{center}
Note that the SROC curve is not extrapolated beyond the range of the original data. 


\section{A bivariate approach}
Typically the sensitivity and specificity of a diagnostic test depend on each other through a cut-off value: as the cut-off is varied to, say, increase the sensitivity, the specificity often decreases. So in a meta-analytic setting one will often observe (negatively) correlated sensitivities and specificities. This observation can (equivalently) also be state as a (positive) correlation of sensitivities and false positive rates. Since these two quantities are interrelated, bivariate approaches to the meta-analysis of diagnostic accuracy have been quite successful (TODO: zitate). 

One typically assumes a binomial model conditional on a primary studies true sensitivity and false positive rates, and a bivariate normal model for the logit-transformed pairs of sensitivities and false positive rates. There are two ways to cast the final model: as a non-linear mixed model (TODO: Zitat) or as linear mixed model (TODO: Zitat). The latter approach is implemented in \texttt{mada}'s \texttt{reitsma} function, so we give some more details. Let $p_i$ and $u_i$ denote the $i$th study's true sensitivity and false positive rate respectively, and let $\hat p_i$ and $\hat u_i$ denote their estimates from the observed frequencies. Then, since a binomial model is assumed conditional on the true $p_i$, the variance of $\logit(\hat p_i)$ can be approximated by
\[
\frac{\hat p_i(1 - \hat p_i)}{m_i},
\]
and the variance of $\logit(\hat u_i)$ is then
\[
\frac{\hat u_i(1 - \hat u_i)}{n_i}.
\]
So on the within study level one assumes, conditional on $p_i$ and $u_i$, that the observed variation is described by these variances and a normal model; let $D_i$ denote a diagonal 2$\times$2 matrix with the two variances on the diagnoal. On the study level, one assumes that a global mean

\[\mu=(\mu_1,\mu_2)^\T \]
 and covariance matrix 
\[
\Sigma=\left(
\begin{array}{cc}
\sg_1^2   & 		\sg \\
\sg		&  \sg_2^2
\end{array}\right)
\]
describe the heterogeneity of the pairs $(\logit(p_i),\logit(u_i))$. So the model for the $i$th study is then
\[
(\logit(\hat p_i),\logit(\hat u_i))^\T \sim \mathrm{N}(\mu, \Sigma + D_i).
\]
Fitting this model in \texttt{mada} is similar to the other model fitting functions:
<<>>=
(fit.reitsma <- reitsma(AuditC))
@
The \texttt{print} method for \texttt{reitsma} objects has a scarce output. More information is offered by the \texttt{summary} method:
<<>>=
summary(fit.reitsma)
@
Note the sensitivity and false positive rate returned in this summary are just the back transformed $\mu_1$ and $\mu_2$. One can then proceed to plot the SROC curve of this model. By default the point estimate of the pair of sensitivity and false positive rate is also plotted together with a confidence region. In the following example the SROC curve is plotted a bit thicker using the \texttt{sroclwd} argument, a caption is added to the plot and also the data and a legend. By default the SROC curve is not extrapolated beyond the range of the orginal data.

\begin{center}
<<fig=TRUE>>=
plot(fit.reitsma, sroclwd = 2,
     main = "SROC curve (bivariate model) for AUDIT-C data")
points(fpr(AuditC), sens(AuditC), pch = 2)
legend("bottomright", c("data", "summary estimate", "SROC", "conf. region"), pch = c(2,1,NA,NA), lwd = c(NA,NA, 2,1))
@
\end{center}

\subsection{Using \texttt{mada} to compare SROC curves}
We show how to compare SROC curves. (TODO: Zitat) conducted a meta-analysis to (among other things) investigate the efficacy of self administered and interviewer administered questionnaires to detect nicotine use. The data sets \texttt{SAQ} and \texttt{IAQ} are the respective subsets of this data. First one fits bivariate models to the data sets:
<<>>=
data(IAQ)
data(SAQ)
fit.IAQ <- reitsma(IAQ)
fit.SAQ <- reitsma(SAQ)
@
Then one plots the SROC curves of

\section{Further development of \texttt{mada}}
In the future \texttt{mada} will provide functions for meta regression of diagnostic accuracy and will incorporate the mixture approach of (TODO: Zitat) to the meta analysis of $\theta$ as well as the bivariate approach based on the $t_\alpha$ transformation of (TODO: ).

(TODO: bibliographie)

\end{document}
